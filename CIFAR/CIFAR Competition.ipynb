{
 "metadata": {
  "name": "",
  "signature": "sha256:e53310547c76282c8781ca0e0758da6d0926ef3ae55575dd0afe601199a156e5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# THE CIFAR CHALLENGE - Kaggle"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook present my studies related to the [CIFAR-10](https://www.kaggle.com/c/cifar-10) Kaggle Competition. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### The features\n",
      "On the first reading of the competition and what it is about, it comes to our mind that we will have at least 2 problems:\n",
      "\n",
      "+ the features come from images - hard to work on\n",
      "+ there are lots of pictures on the train data and even more on the test - it took me more than 45 minutes to extract only the train zip file and another 46 minutes to get all the data inside memory\n",
      "\n",
      "As I am the kind of person that will usually spend 1 hour to do a process that runs in 10 mins instead of spending 10 mins to make a program that will take 1 hour to run, I have constructed a package that will get all the files from the 7z and put in memory, instead of decompressing them. That reduces the time to 1 minute.\n",
      "\n",
      "I have created the package called [https://github.com/AdrianoW/7z_on_array](7z_on_array). Version 0.1 at most. I'll use it here."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "from matplotlib import pyplot as plt\n",
      "import Sevenz_on_array as sz\n",
      "import numpy as np\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 177
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TEST_FILE = '/Users/adrianowalmeida/Documents/Box Sync/Box Sync/DSR/Machine Learning/Kaggle/CIFAR/test.7z'\n",
      "TEST_DIR = '/Users/adrianowalmeida/Documents/Box Sync/Box Sync/DSR/Machine Learning/Kaggle/CIFAR/test/*.png'\n",
      "TRAIN_FILE = '/Users/adrianowalmeida/Documents/Box Sync/Box Sync/DSR/Machine Learning/Kaggle/CIFAR/train.7z'\n",
      "TRAIN_DIR = '/Users/adrianowalmeida/Documents/Box Sync/Box Sync/DSR/Machine Learning/Kaggle/CIFAR/train/*.png'\n",
      "TARGET = '/Users/adrianowalmeida/Documents/Box Sync/Box Sync/DSR/Machine Learning/Kaggle/CIFAR/trainLabels.csv'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 178
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "# importing training and labels\n",
      "f_info = sz.get_files_info(TRAIN_FILE)\n",
      "raw_data = sz.uncompress_file(TRAIN_FILE)\n",
      "image = sz.get_files_array(f_info, raw_data)\n",
      "image =np.array(image)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 45.5 s, sys: 564 ms, total: 46.1 s\n",
        "Wall time: 54.8 s\n"
       ]
      }
     ],
     "prompt_number": 185
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# labels\n",
      "target = pd.read_csv(TARGET)\n",
      "target = target.label.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 186
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "the downsize of this approach is that 7zip makes a mess with ordering. It considers 1,10,11,2,21,3....."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# convert the file names to int and then create a sorted index \n",
      "sort_index = np.copy(f_info[:,2])\n",
      "sort_index = np.argsort(np.array([ int(i[:-4])  for i in sort_index ]))\n",
      "sort_index"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 188,
       "text": [
        "array([    0, 11111, 22222, ..., 44442, 44443, 44448])"
       ]
      }
     ],
     "prompt_number": 188
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# apply sorted index\n",
      "f_info = f_info[sort_index]\n",
      "image = image[sort_index, :,:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 189
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# reshape images so that we can use them on machine learning\n",
      "data = np.array([ x.reshape(-1) for x in image])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 190
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create the final files\n",
      "train = {}\n",
      "train['image'] = image\n",
      "train['data'] = data\n",
      "train['target'] = target"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 194
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print train['target']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['frog' 'truck' 'truck' ..., 'truck' 'automobile' 'automobile']\n"
       ]
      }
     ],
     "prompt_number": 195
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print train['image'].shape\n",
      "print train['data'].shape\n",
      "print train['target'].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(50000, 32, 32, 3)\n",
        "(50000, 3072)\n",
        "(50000,)\n"
       ]
      }
     ],
     "prompt_number": 197
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Machine Learning"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As this problem is all about bytes, I cannot just look at data and think I can find a pattern. So lets start training strait away"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd # load data\n",
      "# models\n",
      "from sklearn.S import  # logistic regression model\n",
      "from sklearn.ensemble import RandomForestClassifier # ramdom forest\n",
      "# helpers\n",
      "from sklearn.grid_search import GridSearchCV # auto tune parameters\n",
      "# validation\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "import sklearn.metrics as metrics"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 113
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#reoder files according to files name\n",
      "f_names = f_info"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Amount processed 0 %\n",
        "Amount processed 10.0 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Amount processed 20.0 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Amount processed 30.0 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Amount processed 40.0 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Amount processed 50.0 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Amount processed 60.0 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Amount processed 70.0 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Amount processed 80.0 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Amount processed 90.0 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished loading file"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "CPU times: user 8min 15s, sys: 1min 4s, total: 9min 19s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Wall time: 46min 1s\n"
       ]
      }
     ],
     "prompt_number": 110
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# check if file is there and the size\n",
      "!ls -lh 'CIFAR.pk1'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-rw-r--r--  1 adrianowalmeida  staff   1,7G 30 Ago 01:10 CIFAR.pk1\r\n"
       ]
      }
     ],
     "prompt_number": 114
    }
   ],
   "metadata": {}
  }
 ]
}