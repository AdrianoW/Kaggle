{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mylib.utils as mu\n",
    "from lasagne.layers import InputLayer, DenseLayer\n",
    "from lasagne.nonlinearities import softmax, rectify\n",
    "from lasagne.objectives import binary_crossentropy\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lasagne.layers import DenseLayer\n",
    "from lasagne.layers import InputLayer\n",
    "from lasagne.layers import DropoutLayer\n",
    "from lasagne.nonlinearities import softmax, sigmoid, tanh\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import NeuralNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:08:59 10/07/15 BRT - Loaded info group scores_class, current shape of data (634, 14)\n",
      "(2, 13)\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "import numpy as np\n",
    "# load data\n",
    "comb = ['balance', 'scores_class']\n",
    "data = mu.load_data(comb)\n",
    "target = mu.load_target_data()\n",
    "\n",
    "# split the data to check the training\n",
    "X_train, X_val, y_train, y_val = mu.split_data(data, target)\n",
    "\n",
    "X = X_train.values.copy()\n",
    "y = y_train.astype(np.int32)\n",
    "num_classes = 2\n",
    "num_features = X.shape[1]\n",
    "print(num_classes, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layers0 = [('input', InputLayer),\n",
    "           ('dense0', DenseLayer),\n",
    "           #('dense1', DenseLayer),\n",
    "           ('output', DenseLayer)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net0 = NeuralNet(layers=layers0,\n",
    "                 \n",
    "                 input_shape=(None, num_features),\n",
    "                 dense0_num_units=400,\n",
    "                 #dropout_p=0.5,\n",
    "                 #dense1_num_units=200,\n",
    "                 output_num_units=num_classes,\n",
    "                 output_nonlinearity=softmax,\n",
    "                 #objective_loss_function= binary_crossentropy,\n",
    "                 \n",
    "                 update=nesterov_momentum,\n",
    "                 update_learning_rate=0.01,\n",
    "                 update_momentum=0.9,\n",
    "                 \n",
    "                 eval_size=0.2,\n",
    "                 verbose=1,\n",
    "                 max_epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  input             \t(None, 13)          \tproduces      13 outputs\n",
      "  dense0            \t(None, 400)         \tproduces     400 outputs\n",
      "  output            \t(None, 2)           \tproduces       2 outputs\n",
      "  epoch     train loss    valid loss    train/val    valid acc  dur\n",
      "-------  -------------  ------------  -----------  -----------  -----\n",
      "      1  \u001b[94m9483856.00000\u001b[0m   \u001b[32m14616.75781\u001b[0m    648.83447      0.43478  0.00s\n",
      "      2  \u001b[94m263296.50000\u001b[0m   39980.99219      6.58554      0.43478  0.00s\n",
      "      3   \u001b[94m47304.88281\u001b[0m   63109.15625      0.74957      0.43478  0.00s\n",
      "      4  478196.90625   81252.69531      5.88530      0.43478  0.00s\n",
      "      5   83521.64062   93633.02344      0.89201      0.43478  0.00s\n",
      "      6   94063.76562  101843.81250      0.92361      0.43478  0.00s\n",
      "      7  101043.95312  107323.78906      0.94149      0.43478  0.00s\n",
      "      8  105636.68750  110948.20312      0.95213      0.43478  0.00s\n",
      "      9  108722.64062  113346.12500      0.95921      0.43478  0.00s\n",
      "     10  110758.07812  114683.96875      0.96577      0.43478  0.00s\n",
      "     11  112027.86719  115734.54688      0.96797      0.43478  0.00s\n",
      "     12  112932.09375  116463.87500      0.96967      0.43478  0.00s\n",
      "     13  113513.66406  116916.23438      0.97090      0.43478  0.00s\n",
      "     14  113894.84375  117212.33594      0.97170      0.43478  0.00s\n",
      "     15  114144.15625  117405.76562      0.97222      0.43478  0.00s\n",
      "     16  114308.22656  117531.77344      0.97257      0.43478  0.00s\n",
      "     17  114414.09375  117613.51562      0.97280      0.43478  0.00s\n",
      "     18  114482.64844  117666.18750      0.97294      0.43478  0.00s\n",
      "     19  114526.69531  117699.78906      0.97304      0.43478  0.00s\n",
      "     20  114554.67188  117720.89062      0.97310      0.43478  0.00s\n",
      "     21  114572.09375  117733.76562      0.97315      0.43478  0.00s\n",
      "     22  114582.58594  117741.25781      0.97317      0.43478  0.00s\n",
      "     23  114588.54688  117745.21875      0.97319      0.43478  0.00s\n",
      "     24  114591.52344  117746.85938      0.97320      0.43478  0.00s\n",
      "     25  114592.54688  117746.96875      0.97321      0.43478  0.00s\n",
      "     26  114592.28125  117746.09375      0.97322      0.43478  0.00s\n",
      "     27  114591.16406  117744.55469      0.97322      0.43478  0.00s\n",
      "     28  114589.51562  117742.59375      0.97322      0.43478  0.00s\n",
      "     29  114587.49219  117740.35156      0.97322      0.43478  0.00s\n",
      "     30  114585.23438  117737.89844      0.97322      0.43478  0.01s\n",
      "     31  114582.82031  117735.35938      0.97322      0.43478  0.00s\n",
      "     32  114580.30469  117732.70312      0.97322      0.43478  0.00s\n",
      "     33  114577.71875  117730.02344      0.97322      0.43478  0.00s\n",
      "     34  114575.08594  117727.31250      0.97322      0.43478  0.00s\n",
      "     35  114572.44531  117724.56250      0.97322      0.43478  0.00s\n",
      "     36  114569.76562  117721.79688      0.97322      0.43478  0.00s\n",
      "     37  114567.06250  117719.01562      0.97322      0.43478  0.00s\n",
      "     38  114564.35938  117716.23438      0.97322      0.43478  0.00s\n",
      "     39  114561.65625  117713.45312      0.97322      0.43478  0.00s\n",
      "     40  114558.93750  117710.66406      0.97322      0.43478  0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNet(X_tensor_type=<function matrix at 0x10dcaf2a8>,\n",
       "     batch_iterator_test=<nolearn.lasagne.base.BatchIterator object at 0x10e3406d0>,\n",
       "     batch_iterator_train=<nolearn.lasagne.base.BatchIterator object at 0x10e315810>,\n",
       "     custom_score=None, dense0_num_units=400, eval_size=0.2,\n",
       "     input_shape=(None, 13),\n",
       "     layers=[('input', <class 'lasagne.layers.input.InputLayer'>), ('dense0', <class 'lasagne.layers.dense.DenseLayer'>), ('output', <class 'lasagne.layers.dense.DenseLayer'>)],\n",
       "     loss=None, max_epochs=40, more_params={},\n",
       "     objective=<class 'lasagne.objectives.Objective'>,\n",
       "     objective_loss_function=<function categorical_crossentropy at 0x10de79320>,\n",
       "     on_epoch_finished=[<nolearn.lasagne.util.PrintLog instance at 0x1106db7a0>],\n",
       "     on_training_finished=[],\n",
       "     output_nonlinearity=<function softmax at 0x10e1e4c08>,\n",
       "     output_num_units=2, regression=False,\n",
       "     update=<function nesterov_momentum at 0x10e312a28>,\n",
       "     update_learning_rate=0.01, update_momentum=0.9,\n",
       "     use_label_encoder=False, verbose=1,\n",
       "     y_tensor_type=TensorType(int32, vector))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net0.fit(X.astype(np.float32), np.ravel(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_prob = net0.predict_proba(X_val.values.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
