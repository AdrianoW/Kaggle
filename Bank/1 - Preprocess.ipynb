{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Preprocess\n",
    "This notebook preprocess the data. The basic steps are:\n",
    "\n",
    "   - Load and join the inputs\n",
    "   - Split the columns into column groups. That will make it easier to process different sets of columns\n",
    "   - Preprocess the groups, binarizing, normalizing and creating new features as necessary\n",
    "   - Save each group into a different file inside **Processed** folder\n",
    "   - Save the index to the train and test dataset into **Processed** folder\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import mylib.utils as mu\n",
    "from mylib.utils import (print_time, get_numerical_cols, years_passed, days_passed, \n",
    "    save_fields_dict, load_fields_dict, Scaler, binarize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the input and join databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:51:07 10/08/15 BRT - Loaded information. Loan #: 1285 Applications #:647\n"
     ]
    }
   ],
   "source": [
    "# load the datasets\n",
    "application_raw = pd.read_excel('./input/onsite homework v1.xlsx', 1)\n",
    "loan_raw = pd.read_excel('./input/onsite homework v1.xlsx', 2)\n",
    "print_time('Loaded information. Loan #: %d Applications #:%d' %(loan_raw.index.size, application_raw.index.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:51:07 10/08/15 BRT - Creating customer_id field to join loan and application\n"
     ]
    }
   ],
   "source": [
    "# create the customer id on loan to join with application\n",
    "print_time('Creating customer_id field to join loan and application')\n",
    "loan = loan_raw.copy()\n",
    "loan['customer_id']=loan.apply(lambda l: l[0][:-3].lower(), axis = 1)\n",
    "loan['loan_no']=loan.apply(lambda l: int(l[0][-2:]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:51:07 10/08/15 BRT - Number of clients with 2 loans 16\n",
      "02:51:07 10/08/15 BRT - Removing first loan. Nr of lines 1285\n",
      "02:51:07 10/08/15 BRT - Removed first loan. Nr of lines 1269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/pandas/core/frame.py:1825: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"DataFrame index.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# found that there is 16 with 2 loans. will keep only the second\n",
    "idx_more_than_once = (loan.groupby(['customer_id'])['flgGood'].count() >1)\n",
    "idx_more_than_once = idx_more_than_once[idx_more_than_once == True]\n",
    "print_time('Number of clients with 2 loans %d' %idx_more_than_once.count())\n",
    "print_time('Removing first loan. Nr of lines %d' % loan.idLoan.count())\n",
    "loan.drop(loan[loan.customer_id.isin(idx_more_than_once.index)][loan.loan_no ==1].index, inplace = True)\n",
    "print_time('Removed first loan. Nr of lines %d' %loan.idLoan.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:51:07 10/08/15 BRT - Preprocessing application\n"
     ]
    }
   ],
   "source": [
    "# preprocess application\n",
    "print_time('Preprocessing application')\n",
    "application = application_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:51:07 10/08/15 BRT - Final data created. Nr of lines 634\n"
     ]
    }
   ],
   "source": [
    "# create data \n",
    "data = pd.merge(application, loan, on='customer_id')\n",
    "print_time('Final data created. Nr of lines %d' %data.index.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:51:07 10/08/15 BRT - Number of lines discarded 13\n"
     ]
    }
   ],
   "source": [
    "# 13 lines lost. Check if it is correct\n",
    "print_time('Number of lines discarded %d' \n",
    "      %application[~application.customer_id.isin(data.customer_id)].customer_id.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# target variable\n",
    "data.rename(columns={'flgGood':'target'}, inplace=True)\n",
    "data['target'] = [1 if d== 'Good' else 0 for d in data.target]\n",
    "#del data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create group of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cols names helpers\n",
    "cols=dict(\n",
    "    raw_scores = [ col for col in data.columns.tolist() if ('raw' in col)],\n",
    "    personal = [u'Facebook profile duration', u'residence_duration', u'home_phone_type',\n",
    "                 u'other_phone_type', u'Gender_facebook', u'birth_date', u'Title'],\n",
    "    location = [u'City', u'State',],\n",
    "    address = ['CEP', 'StreetAddress', 'Latitude','Longitude'],\n",
    "    #dates = [u'application_when',  u'birth_date'],\n",
    "    #ids = ['customer_id', 'idLoan'],\n",
    "    personal_unique = ['CPF', 'Occupation', 'email', 'TelephoneNumber'],\n",
    "    name = ['GivenName', 'MiddleInitial', 'Surname'],\n",
    "    others = ['status'],\n",
    "    balance = [u'residence_rent_or_own', u'monthly_rent_amount', u'monthly_income_amount', u'bank_account_duration'],\n",
    "    nu_info = ['loan_no', u'Credit_Line_approved', u'Credit_Line_requested', u'application_when']\n",
    ")\n",
    "numeric, non_numeric = get_numerical_cols(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:51:07 10/08/15 BRT - Feature engineering and cleaning\n",
      "02:51:07 10/08/15 BRT - Processing personal info\n"
     ]
    }
   ],
   "source": [
    "# dictionary of transformed data\n",
    "trans_data = {}\n",
    "print_time('Feature engineering and cleaning')\n",
    "\n",
    "# set the index to the id so that all child keep the index\n",
    "data.set_index('customer_id', inplace=True)\n",
    "\n",
    "# fill the secondary type with string NI - Not Informed\n",
    "data.other_phone_type.fillna('NI', inplace=True)\n",
    "data.bank_account_duration.fillna('NI', inplace=True)\n",
    "#data.Occupation.fillna('NI', inplace=True)\n",
    "\n",
    "# binarize categoricals\n",
    "print_time('Processing personal info')\n",
    "personal = pd.get_dummies(data[cols['personal']])\n",
    "\n",
    "# transform date of birth to age\n",
    "personal['age'] = personal.birth_date.apply(years_passed)\n",
    "del personal['birth_date']\n",
    "\n",
    "# create a new feature related to money and age\n",
    "personal['age_money_ratio_class'] = binarize( data[u'monthly_income_amount']/personal[u'age'])\n",
    "\n",
    "trans_data['personal'] = personal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:51:07 10/08/15 BRT - Normalizing raw scores\n"
     ]
    }
   ],
   "source": [
    "# scale the numerical mean 0, sd 1\n",
    "print_time('Normalizing raw scores')\n",
    "scl = Scaler(cols['raw_scores'])\n",
    "raw_scores = scl.fit_transform(data)\n",
    "trans_data['raw_scores'] = raw_scores[cols['raw_scores']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:51:07 10/08/15 BRT - Processing balance information\n"
     ]
    }
   ],
   "source": [
    "print_time('Processing balance information')\n",
    "balance = data[cols['balance']].copy()\n",
    "balance.residence_rent_or_own = [1 if r else 0 for r in balance.residence_rent_or_own]\n",
    "balance['rent_income_ratio'] = balance.monthly_rent_amount/balance.monthly_income_amount\n",
    "balance = pd.get_dummies(balance)\n",
    "trans_data['balance'] = balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:51:07 10/08/15 BRT - Processing Nu info\n"
     ]
    }
   ],
   "source": [
    "print_time('Processing Nu info')\n",
    "nu_info = data[cols['nu_info']].copy()\n",
    "nu_info['credit_approved_ratio'] = nu_info.Credit_Line_approved /nu_info.Credit_Line_requested \n",
    "nu_info['days_since_application'] = nu_info.application_when.apply(days_passed)\n",
    "nu_info['credit_income_ratio'] = nu_info.Credit_Line_approved/balance.monthly_income_amount\n",
    "nu_info['liquid_income_ratio'] = nu_info.Credit_Line_approved/(balance.monthly_income_amount-balance.monthly_rent_amount)\n",
    "nu_info['money_to_spare_class'] =  binarize(data[u'monthly_income_amount']-data[u'monthly_rent_amount']-nu_info[u'Credit_Line_approved'])\n",
    "del nu_info['application_when']\n",
    "trans_data['nu_info'] = nu_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:51:07 10/08/15 BRT - Processing location information\n"
     ]
    }
   ],
   "source": [
    "print_time('Processing location information')\n",
    "location = data[cols['location']].copy()\n",
    "location = pd.get_dummies(location)\n",
    "trans_data['location'] = location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:51:07 10/08/15 BRT - Creating new features - scores classes\n"
     ]
    }
   ],
   "source": [
    "print_time('Creating new features - scores classes')\n",
    "scores = pd.DataFrame(index=data.index)\n",
    "scores_list = [u'raw_unit4_score', u'raw_lexisnexis_score',\n",
    "        u'raw_TU_score', u'raw_FICO_money_score']\n",
    "names_list = []\n",
    "for col in scores_list:\n",
    "    names_list.append(col+'_class')\n",
    "    scores[col+'_class'] = binarize(data[col])\n",
    "trans_data['scores_class'] = scores\n",
    "cols['scores_class'] = names_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the data to the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:51:07 10/08/15 BRT - Saving data in Processed folder\n"
     ]
    }
   ],
   "source": [
    "# save full processed\n",
    "print_time('Saving data in Processed folder')\n",
    "data.to_csv('./Processed/full_data.csv',  encoding='utf-8')\n",
    "data['target'].to_csv('./Processed/target.csv',  encoding='utf-8', header=True)\n",
    "\n",
    "# save files for each set of generated colums\n",
    "for k,v in cols.iteritems():\n",
    "    # save transformed data if exists, else save the original one\n",
    "    if k in trans_data:\n",
    "        # replace ' ' from column names with _\n",
    "        trans_data[k].columns = [ col.replace(' ', '_').replace('-', '_').replace('+', '') \n",
    "                                 for col in trans_data[k].columns.tolist() ]\n",
    "        trans_data[k].to_csv('./Processed/{}.csv'.format(k), encoding='utf-8')\n",
    "    else:\n",
    "        data[v].to_csv('./Processed/{}.csv'.format(k), encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the dictionary for future use\n",
    "save_fields_dict(cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the common seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:51:08 10/08/15 BRT - Common seed saved: 56909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "56909"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#56909 seed to run the example\n",
    "mu.save_seed(56909)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
