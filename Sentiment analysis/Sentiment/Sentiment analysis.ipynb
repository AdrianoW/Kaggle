{
 "metadata": {
  "name": "",
  "signature": "sha256:4654523857644b0c62ded779e4ba9a8b830f6cb154da5a90b83d410b6e91edf1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "import pandas as pd\n",
      "import sklearn\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train = pd.read_csv('Data/train.tsv', delimiter='\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train.count()\n",
      "train.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>PhraseId</th>\n",
        "      <th>SentenceId</th>\n",
        "      <th>Sentiment</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td> 156060.000000</td>\n",
        "      <td> 156060.000000</td>\n",
        "      <td> 156060.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td>  78030.500000</td>\n",
        "      <td>   4079.732744</td>\n",
        "      <td>      2.063578</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td>  45050.785842</td>\n",
        "      <td>   2502.764394</td>\n",
        "      <td>      0.893832</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>      1.000000</td>\n",
        "      <td>      1.000000</td>\n",
        "      <td>      0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td>  39015.750000</td>\n",
        "      <td>   1861.750000</td>\n",
        "      <td>      2.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td>  78030.500000</td>\n",
        "      <td>   4017.000000</td>\n",
        "      <td>      2.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td> 117045.250000</td>\n",
        "      <td>   6244.000000</td>\n",
        "      <td>      3.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td> 156060.000000</td>\n",
        "      <td>   8544.000000</td>\n",
        "      <td>      4.000000</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "            PhraseId     SentenceId      Sentiment\n",
        "count  156060.000000  156060.000000  156060.000000\n",
        "mean    78030.500000    4079.732744       2.063578\n",
        "std     45050.785842    2502.764394       0.893832\n",
        "min         1.000000       1.000000       0.000000\n",
        "25%     39015.750000    1861.750000       2.000000\n",
        "50%     78030.500000    4017.000000       2.000000\n",
        "75%    117045.250000    6244.000000       3.000000\n",
        "max    156060.000000    8544.000000       4.000000"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# check if the database is not unbalanced\n",
      "train['Sentiment'].value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "2    79582\n",
        "3    32927\n",
        "1    27273\n",
        "4     9206\n",
        "0     7072\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# amount of  phrases per sentences\n",
      "train.groupby(['SentenceId'])['PhraseId'].count().hist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "<matplotlib.axes._subplots.AxesSubplot at 0x10a557510>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEACAYAAAC08h1NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10a5579d0>"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "array([[1, 1,\n",
        "        'A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .',\n",
        "        1],\n",
        "       [2, 1,\n",
        "        'A series of escapades demonstrating the adage that what is good for the goose',\n",
        "        2],\n",
        "       [3, 1, 'A series', 2],\n",
        "       ..., \n",
        "       [156058, 8544, 'avuncular chortles', 3],\n",
        "       [156059, 8544, 'avuncular', 2],\n",
        "       [156060, 8544, 'chortles', 2]], dtype=object)"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.cross_validation import ShuffleSplit"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create pipeline of transformation\n",
      "tfidf_ngrams = TfidfVectorizer(ngram_range=(1, 3),\n",
      "                      analyzer=\"word\", binary=False)\n",
      "clf = MultinomialNB()\n",
      "pipeline = Pipeline([('vect', tfidf_ngrams), ('clf', clf)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create X and Y\n",
      "X = train.Phrase\n",
      "Y = train.Sentiment"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pipeline.fit(X,Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 43,
       "text": [
        "Pipeline(steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, charset=None,\n",
        "        charset_error=None, decode_error=u'strict',\n",
        "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
        "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
        "        ngram_range=(1, 3), norm=...rue,\n",
        "        vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_score = pipeline.score(X, Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 46,
       "text": [
        "0.7119697552223504"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv = ShuffleSplit(n=len(X), n_iter=3, test_size=0.3, random_state=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 51,
       "text": [
        "ShuffleSplit(156060, n_iter=10, test_size=0.3, random_state=0)"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for x,y in cv:\n",
      "    print x.shape\n",
      "    print y.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(109242,)\n",
        "(46818,)\n",
        "(109242,)\n",
        "(46818,)\n",
        "(109242,)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(46818,)\n",
        "(109242,)\n",
        "(46818,)\n",
        "(109242,)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(46818,)\n",
        "(109242,)\n",
        "(46818,)\n",
        "(109242,)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(46818,)\n",
        "(109242,)\n",
        "(46818,)\n",
        "(109242,)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(46818,)\n",
        "(109242,)\n",
        "(46818,)\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test = pd.read_csv('Data/test.tsv', delimiter='\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result = pipeline.predict(test.Phrase)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "final = pd.DataFrame(columns=['PhraseId','Sentiment'])\n",
      "final.PhraseId = test.PhraseId\n",
      "final.Sentiment = result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "final"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>PhraseId</th>\n",
        "      <th>Sentiment</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0    </th>\n",
        "      <td> 156061</td>\n",
        "      <td> 3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1    </th>\n",
        "      <td> 156062</td>\n",
        "      <td> 3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2    </th>\n",
        "      <td> 156063</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3    </th>\n",
        "      <td> 156064</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4    </th>\n",
        "      <td> 156065</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5    </th>\n",
        "      <td> 156066</td>\n",
        "      <td> 3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6    </th>\n",
        "      <td> 156067</td>\n",
        "      <td> 3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7    </th>\n",
        "      <td> 156068</td>\n",
        "      <td> 3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8    </th>\n",
        "      <td> 156069</td>\n",
        "      <td> 3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9    </th>\n",
        "      <td> 156070</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10   </th>\n",
        "      <td> 156071</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11   </th>\n",
        "      <td> 156072</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12   </th>\n",
        "      <td> 156073</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13   </th>\n",
        "      <td> 156074</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14   </th>\n",
        "      <td> 156075</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15   </th>\n",
        "      <td> 156076</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16   </th>\n",
        "      <td> 156077</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17   </th>\n",
        "      <td> 156078</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18   </th>\n",
        "      <td> 156079</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19   </th>\n",
        "      <td> 156080</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20   </th>\n",
        "      <td> 156081</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>21   </th>\n",
        "      <td> 156082</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>22   </th>\n",
        "      <td> 156083</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>23   </th>\n",
        "      <td> 156084</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>24   </th>\n",
        "      <td> 156085</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25   </th>\n",
        "      <td> 156086</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>26   </th>\n",
        "      <td> 156087</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>27   </th>\n",
        "      <td> 156088</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>28   </th>\n",
        "      <td> 156089</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>29   </th>\n",
        "      <td> 156090</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>...</th>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66262</th>\n",
        "      <td> 222323</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66263</th>\n",
        "      <td> 222324</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66264</th>\n",
        "      <td> 222325</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66265</th>\n",
        "      <td> 222326</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66266</th>\n",
        "      <td> 222327</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66267</th>\n",
        "      <td> 222328</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66268</th>\n",
        "      <td> 222329</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66269</th>\n",
        "      <td> 222330</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66270</th>\n",
        "      <td> 222331</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66271</th>\n",
        "      <td> 222332</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66272</th>\n",
        "      <td> 222333</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66273</th>\n",
        "      <td> 222334</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66274</th>\n",
        "      <td> 222335</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66275</th>\n",
        "      <td> 222336</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66276</th>\n",
        "      <td> 222337</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66277</th>\n",
        "      <td> 222338</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66278</th>\n",
        "      <td> 222339</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66279</th>\n",
        "      <td> 222340</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66280</th>\n",
        "      <td> 222341</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66281</th>\n",
        "      <td> 222342</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66282</th>\n",
        "      <td> 222343</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66283</th>\n",
        "      <td> 222344</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66284</th>\n",
        "      <td> 222345</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66285</th>\n",
        "      <td> 222346</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66286</th>\n",
        "      <td> 222347</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66287</th>\n",
        "      <td> 222348</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66288</th>\n",
        "      <td> 222349</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66289</th>\n",
        "      <td> 222350</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66290</th>\n",
        "      <td> 222351</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66291</th>\n",
        "      <td> 222352</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>66292 rows \u00d7 2 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 74,
       "text": [
        "       PhraseId  Sentiment\n",
        "0        156061          3\n",
        "1        156062          3\n",
        "2        156063          2\n",
        "3        156064          2\n",
        "4        156065          2\n",
        "5        156066          3\n",
        "6        156067          3\n",
        "7        156068          3\n",
        "8        156069          3\n",
        "9        156070          2\n",
        "10       156071          2\n",
        "11       156072          2\n",
        "12       156073          2\n",
        "13       156074          2\n",
        "14       156075          2\n",
        "15       156076          2\n",
        "16       156077          2\n",
        "17       156078          2\n",
        "18       156079          2\n",
        "19       156080          2\n",
        "20       156081          2\n",
        "21       156082          2\n",
        "22       156083          2\n",
        "23       156084          2\n",
        "24       156085          2\n",
        "25       156086          2\n",
        "26       156087          2\n",
        "27       156088          2\n",
        "28       156089          2\n",
        "29       156090          2\n",
        "...         ...        ...\n",
        "66262    222323          2\n",
        "66263    222324          2\n",
        "66264    222325          2\n",
        "66265    222326          2\n",
        "66266    222327          2\n",
        "66267    222328          2\n",
        "66268    222329          2\n",
        "66269    222330          2\n",
        "66270    222331          2\n",
        "66271    222332          2\n",
        "66272    222333          2\n",
        "66273    222334          2\n",
        "66274    222335          2\n",
        "66275    222336          2\n",
        "66276    222337          2\n",
        "66277    222338          2\n",
        "66278    222339          2\n",
        "66279    222340          2\n",
        "66280    222341          2\n",
        "66281    222342          2\n",
        "66282    222343          2\n",
        "66283    222344          2\n",
        "66284    222345          2\n",
        "66285    222346          2\n",
        "66286    222347          2\n",
        "66287    222348          2\n",
        "66288    222349          2\n",
        "66289    222350          2\n",
        "66290    222351          2\n",
        "66291    222352          2\n",
        "\n",
        "[66292 rows x 2 columns]"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "final.to_csv('output.csv', index= False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "final.to_csv?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV \n",
      "from sklearn.metrics import f1_score\n",
      "from sklearn.ensemble import RandomForestClassifier"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "param_grid = dict(vect__ngram_range=[(1, 1), (1, 2), (1, 3)],\n",
      "                         vect__min_df=[1, 2],\n",
      "                         vect__stop_words=[None, \"english\"],\n",
      "                         vect__smooth_idf=[False, True],\n",
      "                         vect__use_idf=[False, True],\n",
      "                         vect__sublinear_tf=[False, True],\n",
      "                         vect__binary=[False, True],\n",
      "                         clf__alpha=[0, 0.01, 0.05, 0.1, 0.5, 1],\n",
      "                         )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grid_search = RandomizedSearchCV(pipeline,\n",
      "                                  param_distributions=param_grid,\n",
      "                                  cv=cv,\n",
      "                                  #score_func=f1_score,\n",
      "                                  verbose=10)\n",
      "grid_search.fit(X, Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grid_search.best_params_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "{'clf__alpha': 0.5,\n",
        " 'vect__binary': False,\n",
        " 'vect__min_df': 2,\n",
        " 'vect__ngram_range': (1, 3),\n",
        " 'vect__smooth_idf': True,\n",
        " 'vect__stop_words': None,\n",
        " 'vect__sublinear_tf': True,\n",
        " 'vect__use_idf': True}"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grid_search.grid_scores_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "[mean: 0.61298, std: 0.00222, params: {'vect__ngram_range': (1, 2), 'vect__smooth_idf': True, 'vect__sublinear_tf': False, 'vect__binary': False, 'vect__min_df': 2, 'vect__stop_words': 'english', 'vect__use_idf': True, 'clf__alpha': 0.01},\n",
        " mean: 0.62129, std: 0.00236, params: {'vect__ngram_range': (1, 3), 'vect__smooth_idf': False, 'vect__sublinear_tf': True, 'vect__binary': True, 'vect__min_df': 2, 'vect__stop_words': 'english', 'vect__use_idf': False, 'clf__alpha': 0.05},\n",
        " mean: 0.59381, std: 0.00253, params: {'vect__ngram_range': (1, 1), 'vect__smooth_idf': False, 'vect__sublinear_tf': True, 'vect__binary': False, 'vect__min_df': 2, 'vect__stop_words': None, 'vect__use_idf': False, 'clf__alpha': 0.01},\n",
        " mean: 0.63017, std: 0.00164, params: {'vect__ngram_range': (1, 3), 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__binary': False, 'vect__min_df': 2, 'vect__stop_words': None, 'vect__use_idf': True, 'clf__alpha': 0.5},\n",
        " mean: 0.59657, std: 0.00224, params: {'vect__ngram_range': (1, 1), 'vect__smooth_idf': True, 'vect__sublinear_tf': True, 'vect__binary': True, 'vect__min_df': 2, 'vect__stop_words': 'english', 'vect__use_idf': True, 'clf__alpha': 0.01},\n",
        " mean: 0.61686, std: 0.00222, params: {'vect__ngram_range': (1, 2), 'vect__smooth_idf': False, 'vect__sublinear_tf': False, 'vect__binary': True, 'vect__min_df': 2, 'vect__stop_words': None, 'vect__use_idf': False, 'clf__alpha': 0.5},\n",
        " mean: 0.57158, std: 0.00130, params: {'vect__ngram_range': (1, 3), 'vect__smooth_idf': True, 'vect__sublinear_tf': False, 'vect__binary': False, 'vect__min_df': 1, 'vect__stop_words': None, 'vect__use_idf': False, 'clf__alpha': 0},\n",
        " mean: 0.61012, std: 0.00215, params: {'vect__ngram_range': (1, 3), 'vect__smooth_idf': True, 'vect__sublinear_tf': False, 'vect__binary': False, 'vect__min_df': 1, 'vect__stop_words': 'english', 'vect__use_idf': True, 'clf__alpha': 0.01},\n",
        " mean: 0.60731, std: 0.00252, params: {'vect__ngram_range': (1, 2), 'vect__smooth_idf': False, 'vect__sublinear_tf': False, 'vect__binary': False, 'vect__min_df': 1, 'vect__stop_words': None, 'vect__use_idf': True, 'clf__alpha': 1},\n",
        " mean: 0.59003, std: 0.00142, params: {'vect__ngram_range': (1, 3), 'vect__smooth_idf': True, 'vect__sublinear_tf': False, 'vect__binary': False, 'vect__min_df': 1, 'vect__stop_words': None, 'vect__use_idf': False, 'clf__alpha': 0.01}]"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create pipeline of transformation\n",
      "tfidf_ngrams = TfidfVectorizer(\n",
      "binary = False,\n",
      "min_df = 2,\n",
      "ngram_range = (1, 3),\n",
      "smooth_idf = True,\n",
      "stop_words = None,\n",
      "sublinear_tf = True,\n",
      "use_idf = True)\n",
      "clf = [(MultinomialNB(alpha=0.5), \n",
      "pipeline = Pipeline([('vect', tfidf_ngrams), ('clf', clf)])\n",
      "pipeline.fit(X,Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "Pipeline(steps=[('vect', TfidfVectorizer(analyzer=u'word', binary=False, charset=None,\n",
        "        charset_error=None, decode_error=u'strict',\n",
        "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
        "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
        "        ngram_range=(1, 3), norm...rue,\n",
        "        vocabulary=None)), ('clf', MultinomialNB(alpha=0.5, class_prior=None, fit_prior=True))])"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result = pipeline.predict(test.Phrase)\n",
      "final = pd.DataFrame(columns=['PhraseId','Sentiment'])\n",
      "final.PhraseId = test.PhraseId\n",
      "final.Sentiment = result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "final = pd.DataFrame(columns=['PhraseId','Sentiment'])\n",
      "final.PhraseId = test.PhraseId\n",
      "final.Sentiment = result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "final"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>PhraseId</th>\n",
        "      <th>Sentiment</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0    </th>\n",
        "      <td> 156061</td>\n",
        "      <td> 3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1    </th>\n",
        "      <td> 156062</td>\n",
        "      <td> 3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2    </th>\n",
        "      <td> 156063</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3    </th>\n",
        "      <td> 156064</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4    </th>\n",
        "      <td> 156065</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5    </th>\n",
        "      <td> 156066</td>\n",
        "      <td> 3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6    </th>\n",
        "      <td> 156067</td>\n",
        "      <td> 3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7    </th>\n",
        "      <td> 156068</td>\n",
        "      <td> 3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8    </th>\n",
        "      <td> 156069</td>\n",
        "      <td> 3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9    </th>\n",
        "      <td> 156070</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10   </th>\n",
        "      <td> 156071</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11   </th>\n",
        "      <td> 156072</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12   </th>\n",
        "      <td> 156073</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13   </th>\n",
        "      <td> 156074</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14   </th>\n",
        "      <td> 156075</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15   </th>\n",
        "      <td> 156076</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16   </th>\n",
        "      <td> 156077</td>\n",
        "      <td> 3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17   </th>\n",
        "      <td> 156078</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18   </th>\n",
        "      <td> 156079</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19   </th>\n",
        "      <td> 156080</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20   </th>\n",
        "      <td> 156081</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>21   </th>\n",
        "      <td> 156082</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>22   </th>\n",
        "      <td> 156083</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>23   </th>\n",
        "      <td> 156084</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>24   </th>\n",
        "      <td> 156085</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25   </th>\n",
        "      <td> 156086</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>26   </th>\n",
        "      <td> 156087</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>27   </th>\n",
        "      <td> 156088</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>28   </th>\n",
        "      <td> 156089</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>29   </th>\n",
        "      <td> 156090</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>...</th>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66262</th>\n",
        "      <td> 222323</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66263</th>\n",
        "      <td> 222324</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66264</th>\n",
        "      <td> 222325</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66265</th>\n",
        "      <td> 222326</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66266</th>\n",
        "      <td> 222327</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66267</th>\n",
        "      <td> 222328</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66268</th>\n",
        "      <td> 222329</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66269</th>\n",
        "      <td> 222330</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66270</th>\n",
        "      <td> 222331</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66271</th>\n",
        "      <td> 222332</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66272</th>\n",
        "      <td> 222333</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66273</th>\n",
        "      <td> 222334</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66274</th>\n",
        "      <td> 222335</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66275</th>\n",
        "      <td> 222336</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66276</th>\n",
        "      <td> 222337</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66277</th>\n",
        "      <td> 222338</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66278</th>\n",
        "      <td> 222339</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66279</th>\n",
        "      <td> 222340</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66280</th>\n",
        "      <td> 222341</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66281</th>\n",
        "      <td> 222342</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66282</th>\n",
        "      <td> 222343</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66283</th>\n",
        "      <td> 222344</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66284</th>\n",
        "      <td> 222345</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66285</th>\n",
        "      <td> 222346</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66286</th>\n",
        "      <td> 222347</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66287</th>\n",
        "      <td> 222348</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66288</th>\n",
        "      <td> 222349</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66289</th>\n",
        "      <td> 222350</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66290</th>\n",
        "      <td> 222351</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>66291</th>\n",
        "      <td> 222352</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>66292 rows \u00d7 2 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "       PhraseId  Sentiment\n",
        "0        156061          3\n",
        "1        156062          3\n",
        "2        156063          2\n",
        "3        156064          2\n",
        "4        156065          2\n",
        "5        156066          3\n",
        "6        156067          3\n",
        "7        156068          3\n",
        "8        156069          3\n",
        "9        156070          2\n",
        "10       156071          2\n",
        "11       156072          2\n",
        "12       156073          2\n",
        "13       156074          2\n",
        "14       156075          2\n",
        "15       156076          2\n",
        "16       156077          3\n",
        "17       156078          2\n",
        "18       156079          2\n",
        "19       156080          2\n",
        "20       156081          2\n",
        "21       156082          2\n",
        "22       156083          2\n",
        "23       156084          2\n",
        "24       156085          2\n",
        "25       156086          2\n",
        "26       156087          2\n",
        "27       156088          2\n",
        "28       156089          2\n",
        "29       156090          2\n",
        "...         ...        ...\n",
        "66262    222323          2\n",
        "66263    222324          2\n",
        "66264    222325          2\n",
        "66265    222326          2\n",
        "66266    222327          2\n",
        "66267    222328          2\n",
        "66268    222329          2\n",
        "66269    222330          2\n",
        "66270    222331          2\n",
        "66271    222332          2\n",
        "66272    222333          2\n",
        "66273    222334          2\n",
        "66274    222335          2\n",
        "66275    222336          2\n",
        "66276    222337          2\n",
        "66277    222338          2\n",
        "66278    222339          2\n",
        "66279    222340          2\n",
        "66280    222341          2\n",
        "66281    222342          2\n",
        "66282    222343          2\n",
        "66283    222344          2\n",
        "66284    222345          2\n",
        "66285    222346          2\n",
        "66286    222347          2\n",
        "66287    222348          2\n",
        "66288    222349          2\n",
        "66289    222350          2\n",
        "66290    222351          2\n",
        "66291    222352          2\n",
        "\n",
        "[66292 rows x 2 columns]"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "final.to_csv('output_random.csv', index= False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}